{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IpTwQuz5p6K"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook provides code for mixup contrastive learning. The method is illustrated on the gunpoint dataset. The dataset used in this notebook is the gunpoint dataset. But more are available. See https://github.com/alan-turing-institute/sktime/tree/master/sktime/datasets/data for more info.\n",
    "\n",
    "The first two code block clones the sktime Github repo and loads the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5FKoYydvGLG",
    "outputId": "60ca183d-a527-48a9-e7a7-c9ff27e854a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sktime\n",
      "  Downloading sktime-0.11.0-py3-none-any.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<1.22,>=1.21.0\n",
      "  Downloading numpy-1.21.5-cp39-cp39-macosx_10_9_x86_64.whl (17.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.0 MB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.53 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from sktime) (0.54.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from sktime) (0.24.2)\n",
      "Requirement already satisfied: scipy<1.8.0 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from sktime) (1.7.1)\n",
      "Requirement already satisfied: pandas<1.5.0,>=1.1.0 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from sktime) (1.3.4)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from sktime) (0.12.2)\n",
      "Collecting deprecated>=1.2.13\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from deprecated>=1.2.13->sktime) (1.12.1)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.53->sktime) (0.37.0)\n",
      "Collecting numba>=0.53\n",
      "  Downloading numba-0.55.1-cp39-cp39-macosx_10_14_x86_64.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 52.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.53->sktime) (58.0.4)\n",
      "Collecting llvmlite<0.39,>=0.38.0rc1\n",
      "  Downloading llvmlite-0.38.0-cp39-cp39-macosx_10_9_x86_64.whl (25.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.5 MB 2.5 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from pandas<1.5.0,>=1.1.0->sktime) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from pandas<1.5.0,>=1.1.0->sktime) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas<1.5.0,>=1.1.0->sktime) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.24.0->sktime) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.24.0->sktime) (1.1.0)\n",
      "Requirement already satisfied: patsy>=0.5 in /Users/ziyuanzhao/opt/anaconda3/lib/python3.9/site-packages (from statsmodels>=0.12.1->sktime) (0.5.2)\n",
      "Installing collected packages: numpy, llvmlite, numba, deprecated, sktime\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.37.0\n",
      "    Uninstalling llvmlite-0.37.0:\n",
      "      Successfully uninstalled llvmlite-0.37.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.54.1\n",
      "    Uninstalling numba-0.54.1:\n",
      "      Successfully uninstalled numba-0.54.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\u001b[0m\n",
      "Successfully installed deprecated-1.2.13 llvmlite-0.38.0 numba-0.55.1 numpy-1.21.5 sktime-0.11.0\n"
     ]
    }
   ],
   "source": [
    "#@title Clone Git repos\n",
    "\n",
    "!pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "mkzORFQhvWGQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyuanzhao/opt/anaconda3/envs/Sandbox/lib/python3.9/site-packages/sktime/datatypes/_series/_check.py:43: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/Users/ziyuanzhao/opt/anaconda3/envs/Sandbox/lib/python3.9/site-packages/sktime/datatypes/_hierarchical/_check.py:50: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/Users/ziyuanzhao/opt/anaconda3/envs/Sandbox/lib/python3.9/site-packages/sktime/datatypes/_hierarchical/_check.py:51: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n",
      "/Users/ziyuanzhao/opt/anaconda3/envs/Sandbox/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:48: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/Users/ziyuanzhao/opt/anaconda3/envs/Sandbox/lib/python3.9/site-packages/sktime/datatypes/_panel/_check.py:49: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n"
     ]
    }
   ],
   "source": [
    "#@title Load packages and data\n",
    "\n",
    "\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from sktime.datasets import load_gunpoint\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def to_np(x):\n",
    "    return x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mvvnIdG6W8l"
   },
   "source": [
    "## Load data and create Pytorch dataset\n",
    "\n",
    "The following two code block loads the data, converts it to numpy array, before wrapping it in the Pytorch dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "KLEW5ZFz1R_x"
   },
   "outputs": [],
   "source": [
    "#@title load data and convert to numpy array\n",
    "\n",
    "x_tr, y_tr = load_gunpoint(split='train', return_X_y=True)\n",
    "\n",
    "x_tr = pd.DataFrame(x_tr).to_numpy()\n",
    "y_tr = pd.DataFrame(y_tr).to_numpy()\n",
    "\n",
    "x_tr = np.array(np.ndarray.tolist(x_tr), dtype=np.float32)\n",
    "y_tr = np.array(np.ndarray.tolist(y_tr), dtype=np.int32)\n",
    "\n",
    "x_te, y_te = load_gunpoint(split='test', return_X_y=True)\n",
    "\n",
    "\n",
    "x_te = pd.DataFrame(x_te).to_numpy()\n",
    "y_te = pd.DataFrame(y_te).to_numpy()\n",
    "\n",
    "x_te = np.array(np.ndarray.tolist(x_te), dtype=np.float32)\n",
    "y_te = np.array(np.ndarray.tolist(y_te), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 1, 150), (50, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape, y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "window_len = 1500\n",
    "basepath = f'{os.getcwd()}/data'\n",
    "\n",
    "x_tr = np.load(os.path.join(basepath, 'training2017', f\"input_{window_len}.npy\"))\n",
    "y_tr = np.load(os.path.join(basepath, 'training2017', f\"output_{window_len}.npy\"))\n",
    "x_te = np.load(os.path.join(basepath, 'validation', f\"input_{window_len}.npy\"))\n",
    "y_te = np.load(os.path.join(basepath, 'validation', f\"output_{window_len}.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1904, 1, 1500), (1904, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "id": "5tNCbzc23edS"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "\n",
    "        device = 'cpu'\n",
    "        self.x = th.tensor(x, dtype=th.float, device=device)\n",
    "        self.y = th.tensor(y, dtype=th.long, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd4HHFN26mvJ"
   },
   "source": [
    "## Define neural network\n",
    "\n",
    "In this block we define the neural network architecture used. This architecture is based on the fully convolutional network from https://arxiv.org/abs/1611.06455, but with dilation added to each convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "id": "yL5kkfUHve_V"
   },
   "outputs": [],
   "source": [
    "#@title Define FCN\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, n_in):\n",
    "        super(FCN, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(n_in, 128, kernel_size=7, padding=6, dilation=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=5, padding=8, dilation=4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 128, kernel_size=3, padding=8, dilation=8),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.proj_head = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h = self.encoder(x)\n",
    "        out = self.proj_head(h)\n",
    "\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUpO0DPU64zR"
   },
   "source": [
    "## Define loss, training function and evaluation function.\n",
    "\n",
    "The following three code blocks implements the mixup contrastive loss, the training function and the evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "id": "igt1Rxsex4s-"
   },
   "outputs": [],
   "source": [
    "#@title define MixUp Loss\n",
    "\n",
    "class MixUpLoss(th.nn.Module):\n",
    "\n",
    "    def __init__(self, device, batch_size):\n",
    "        super(MixUpLoss, self).__init__()\n",
    "        \n",
    "        self.tau = 0.5\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, z_aug, z_1, z_2, lam):\n",
    "\n",
    "        z_1 = nn.functional.normalize(z_1)\n",
    "        z_2 = nn.functional.normalize(z_2)\n",
    "        z_aug = nn.functional.normalize(z_aug)\n",
    "\n",
    "        labels_lam_0 = lam*th.eye(self.batch_size, device=self.device)\n",
    "        labels_lam_1 = (1-lam)*th.eye(self.batch_size, device=self.device)\n",
    "\n",
    "        labels = th.cat((labels_lam_0, labels_lam_1), 1)\n",
    "\n",
    "        logits = th.cat((th.mm(z_aug, z_1.T),\n",
    "                         th.mm(z_aug, z_2.T)), 1)\n",
    "\n",
    "        loss = self.cross_entropy(logits / self.tau, labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def cross_entropy(self, logits, soft_targets):\n",
    "        return th.mean(th.sum(- soft_targets * self.logsoftmax(logits), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "id": "Vppl1UTbx6xk"
   },
   "outputs": [],
   "source": [
    "#@title mixup model trainer per epoch\n",
    "\n",
    "\n",
    "def train_mixup_model_epoch(model, training_set, test_set, optimizer, alpha, epochs):\n",
    "\n",
    "    device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "    batch_size_tr = len(training_set.x)\n",
    "\n",
    "    LossList, AccList \n",
    "    criterion = MixUpLoss(device, batch_size_tr)\n",
    "\n",
    "    training_generator = DataLoader(training_set, batch_size=batch_size_tr,\n",
    "                                    shuffle=True, drop_last=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for x, y in training_generator:\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x_1 = x\n",
    "            x_2 = x[th.randperm(len(x))]\n",
    "\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "            x_aug = lam * x_1 + (1-lam) * x_2\n",
    "\n",
    "            z_1, _ = model(x_1)\n",
    "            z_2, _ = model(x_2)\n",
    "            z_aug, _ = model(x_aug)\n",
    "\n",
    "            loss= criterion(z_aug, z_1, z_2, lam)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            LossList.append(loss.item())\n",
    "\n",
    "\n",
    "        AccList.append(test_model(model, training_set, test_set))\n",
    "\n",
    "        print(f\"Epoch number: {epoch}\")\n",
    "        print(f\"Loss: {LossList[-1]}\")\n",
    "        print(f\"Accuracy: {AccList[-1]}\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "        if epoch % 10 == 0 and epoch != 0: clear_output()\n",
    "            \n",
    "    return LossList, AccList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "SSwqzgbEx8-B"
   },
   "outputs": [],
   "source": [
    "#@title model evaluation\n",
    "\n",
    "\n",
    "def test_model(model, training_set, test_set):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    N_tr = len(training_set.x)\n",
    "    N_te = len(test_set.x)\n",
    "\n",
    "    training_generator = DataLoader(training_set, batch_size=1,\n",
    "                                    shuffle=True, drop_last=False)\n",
    "    test_generator = DataLoader(test_set, batch_size= 1,\n",
    "                                    shuffle=True, drop_last=False)\n",
    "\n",
    "    H_tr = th.zeros((N_tr, 128))\n",
    "    y_tr = th.zeros((N_tr), dtype=th.long)\n",
    "\n",
    "    H_te = th.zeros((N_te, 128))\n",
    "    y_te = th.zeros((N_te), dtype=th.long)\n",
    "\n",
    "    for idx_tr, (x_tr, y_tr_i) in enumerate(training_generator):\n",
    "        with th.no_grad():\n",
    "            _, H_tr_i = model(x_tr)\n",
    "            H_tr[idx_tr] = H_tr_i\n",
    "            y_tr[idx_tr] = y_tr_i\n",
    "\n",
    "    H_tr = to_np(nn.functional.normalize(H_tr))\n",
    "    y_tr = to_np(y_tr)\n",
    "\n",
    "\n",
    "    for idx_te, (x_te, y_te_i) in enumerate(test_generator):\n",
    "        with th.no_grad():\n",
    "            _, H_te_i = model(x_te)\n",
    "            H_te[idx_te] = H_te_i\n",
    "            y_te[idx_te] = y_te_i\n",
    "\n",
    "    H_te = to_np(nn.functional.normalize(H_te))\n",
    "    y_te = to_np(y_te)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=1).fit(H_tr, y_tr)\n",
    "\n",
    "    return clf.score(H_te, y_te)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux9UVzA97GNi"
   },
   "source": [
    "## Block for training the model\n",
    "\n",
    "This block trains the neural network using mixup contrastive learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "227XYyoHx--y"
   },
   "outputs": [],
   "source": [
    "#@title Experiment number of epochs\n",
    "\n",
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "epochs, LossList, AccList = 200, [], []\n",
    "\n",
    "alpha = 1.0\n",
    "\n",
    "training_set = MyDataset(x_tr[0:2000], y_tr[0:2000])\n",
    "test_set = MyDataset(x_te, y_te)\n",
    "\n",
    "model = FCN(training_set.x.shape[1]).to(device)\n",
    "\n",
    "optimizer = th.optim.Adam(model.parameters())\n",
    "LossListM, AccListM = train_mixup_model_epoch(model, training_set, test_set,\n",
    "                                              optimizer, alpha, epochs)\n",
    "\n",
    "\n",
    "print(f\"Score for alpha = {alpha}: {AccListM[-1]}\")\n",
    "\n",
    "\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.subplot(121)\n",
    "plt.plot(LossListM)\n",
    "plt.title('Loss')\n",
    "plt.subplot(122)\n",
    "plt.plot(AccListM)\n",
    "plt.title('Accuracy')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EtASHNL5nRU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MixupContrastiveLearningExample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
